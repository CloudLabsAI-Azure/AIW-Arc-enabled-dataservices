# Exercise 2: Getting Started with Azure Arc enabled data services 

Duration: - 

In this exercise, you will get familiar with the existing Kubernetes cluster and connect to the data controller and verify the status 

## Task 1: Getting started with the existing Kubernetes cluster 

1. On the JumpVM provided on the left side, launch a **Command Prompt** window (Select search on the taskbar, type cmd, and select Enter).

1. In the command prompt run the following command to get the kubernetes cluster info.

   ```BASH
   kubectl cluster-info
   ```
   ![](./images/kubectl-0.png "azdata")
 
1. Run the following command to list the current namespaces in the cluster, a namespace in Kubernetes creates a logical isolation boundary.

   ```BASH
   kubectl get namespace
   ```

1. A Node is a worker machine in Kubernetes and may be either a virtual or a physical machine, depending on the cluster. Each Node is managed by the Master. A Node can have multiple pods, and the Kubernetes master automatically handles scheduling the pods across the Nodes in the cluster. 
  
   Run the following command to see the status of the kubernetes node.

   ```BASH
   kubectl get nodes
   ```
   
   ![](./images/kubectl-1.png "azdata")
   
1. Now run the following command to get the list of all pods in all namespaces. 
 
   ```BASH
   kubectl get pods -A
   ```
   
   ![](./images/kubectl-2.png "azdata")

1. Run the following command to get the detailed information of a specific pod. Please replace the pod name and namespace name of data controller.

   ```BASH
   kubectl describe pod <pod name> -n <your namespace name>
   ```
   
   ![](./images/kubectl-3.png "azdata")
   
  > **Note**: you can refer to the below links to learn more about kubernetes 
              https://docs.microsoft.com/en-us/learn/modules/aks-workshop/
              https://aksworkshop.io
  
## Task 2: Connect to the data controller using Azure Data Studio/ Azure Data CLI.

In this task, you will learn how to connect to the data controller using Azure Data Studio

1. On your JumpVM open a **Command Prompt** window (Select search on the taskbar, type cmd, and select Enter).

1. Enter the following command at the command prompt.

   ```BASH
   azdata login
   ```
   
   ![](./images/azdata.png "azdata")
   
1. When prompted to enter the Namespace, you can find the Namespace from the Environment details page. Copy the data controller service API endpoint URL value from the output.

   ![](./images/namespace.png "namespace")
   
   ![](./images/endpoint.png "endpoint")

**Connect to Azure Arc Data controller using Azure data studio.**

1. Now on your LabVM open **Azure Data studio** and select **Connections**.

   ![](./images/connection.png "Connection")
   
1. In **Connections** panel under **Azure Arc Controllers** click on Connect Controller.

1. In **Connect to Controller** page enter the following details and click on **Connect**.

   - **Controller URL**: Enter the data controller service API endpoint URL value which you copied earlier 
   
   - **Name** : Enter arcdc
   
   - **Username** : Enter arcuser
   
   - **Password** : Enter Password.1!!
   
     ![](./images/connection1.png "")
    
1. Once Connection is successful, you can see the arc data controller listed under Arc Controllers.

    ![](./images/arcdatacontroller.png "")

## Task 3: Monitor with Data Controller Dashboard

Now that you are connected to a data controller, you can view the dashboards for the data controller and any SQL managed instances or PostgreSQL Hyperscale server group resources that you have.

1. In the **Connections** panel, under **Arc Controllers** right-click on the  arcdc data controller and select **Manage**.

   ![](./images/Mondata-studio01.PNG "")

1. In the Azure Arc Data Controller dashboard, you can see details about the data controller resource such as name, region, connection mode, resource group, subscription, controller endpoint, and namespace.

   ![](./images/arc-dash.PNG "")

1. Click on the Connection Strings tab on the left, you can see a list of pre-constructed connection strings for that server group making it easy for you to copy/paste into various other applications or code.

   ![](./images/Dstudio-constrings.PNG "")

1. You can scale your Azure Arc enabled PostgreSQL Hyperscale server group by adding worker nodes without the downtime and by scaling compute vCores and memory

   ![](./images/Dstudio-compute.PNG "")

1. click on the Diagnose and solve problems tab on the left, you can launch the PostgreSQL troubleshooting notebook.

   ![](./images/Dstudio-diagnose.PNG "")




## After this exercise, you have got familiar with the below exercises
   - Deploying Azure Arc Data controller on to Azure Kubernetes Cluster(AKS) 
   - Getting started with the existing Kubernetes cluster
   - Connect to the data controller using Azure Data Studio/ Azure Data CLI
   - Monitor with Data Controller Dashboard


   
