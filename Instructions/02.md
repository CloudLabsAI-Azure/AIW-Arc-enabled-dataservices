# Exercise 2: Getting Started with Azure Arc enabled data services 

Duration: - 

In this exercise, you will get familiar with the existing Kubernetes cluster and connect to the data controller and verify the status of Azure Arc data controller. You will be deploying Log anaytics workspace in azure portal to see the azure arc resources logs. 

## Task 1: Getting started with the existing Kubernetes cluster 

1. On the JumpVM provided on the left side, launch the **Command Prompt** by double clicking on the cmd shortcut on the desktop.
  
    ![](./images/azuredatastudio.png "azdata")

1. Now the command prompt windows will open up. In the command prompt, run the following command to retrieve the kubernetes cluster info.

   ```BASH
   kubectl cluster-info
   ```
   ![](./images/kubectl-0.png "azdata")
 
1. Run the following command to list the current namespaces in the cluster. A namespace in Kubernetes creates a logical isolation boundary.

   ```BASH
   kubectl get namespace
   ```

1. A node is a worker machine in Kubernetes and may be either a virtual or a physical machine, depending on the cluster. Each Node is managed by the Master. A Node can have multiple pods, and the Kubernetes master automatically handles scheduling the pods across the Nodes in the cluster. 
  
   Run the following command to see the status of the kubernetes node.

   ```BASH
   kubectl get nodes
   ```
   
   ![](./images/kubectl-1.png "azdata")
   
1. Now, run the following command to get the list of all pods in all namespaces. 
 
   ```BASH
   kubectl get pods -A
   ```
   
   ![](./images/kubectl-2.png "azdata")

1. Run the following command to get the detailed information of a specific pod. 

   > **Note**: In the below command, please replace the pod name and namespace name with any pod name and the corresponding namespace from the previous command's output.

   ```BASH
   kubectl describe pod <pod name> -n <your namespace name>
   ```
   
   ![](./images/kubectl-3.png "azdata")
   
  > **Note**: Additionally, you can explore and learn more about kubernetes from the following links - https://docs.microsoft.com/en-us/learn/modules/aks-workshop/, https://aksworkshop.io
  
## Task 2: Connect to the data controller using Azure Data Studio/ Azure Data CLI.

In this task, you will learn how to connect to the data controller using Azure Data Studio and Azure Data CLI

1. First, you will see how to connect to the data controller using Azure Data CLI.

1. On your JumpVM, open a **Command Prompt** window from the desktop shortcut if not already opened.

1. Run the following command at the command prompt.

   ```BASH
   azdata login
   ```
   
   ![](./images/azdata.png "azdata")
   
1. When prompted to enter the Namespace, you can find the Namespace from the Environment details page. Copy the data controller service API endpoint URL value from the output.

   ![](./images/namespace.png "namespace")
   
   ![](./images/endpoint.png "endpoint")
   
1. Now you are logged in to the Azure Arc data controller.

1. Next, you will see how to connect to Azure Arc Data controller using Azure data studio.

1. On your Lab VM, open **Azure Data studio** from the desktop shortcut and select **Connections**.

   ![](./images/arcdc.png "Connection")
   
1. In the **Connections** panel under **Azure Arc Controllers**, click on **Connect Controller**.

1. In the **Connect to Controller** page, provide the following details and click on **Connect**.

   - **Controller URL**: Enter the Azure Arc data controller service API endpoint URL value which you copied earlier 
   
   - **Name** : Enter arcdc
   
   - **Username** : Enter arcuser
   
   - **Password** : Enter Password.1!!
   
     ![](./images/loginarc.png "")
    
1. Once the connection is successful, you can see the Azure Arc data controller listed under Arc Controllers.

    ![](./images/arcdatacontroller.png "")

## Task 3: Monitor with Data Controller Dashboard

Now that you are connected to an Azure Arc data controller, you can view the dashboards for the data controller and any SQL managed instances or PostgreSQL Hyperscale server group resources that you have.

1. In the **Connections** panel, under **Arc Controllers** right-click on the  arcdc data controller and select **Manage**.
   - **Note**: You will see that there is not instance available, this is because we have not deployed any resource on Azure Arc data controller. We will be deploying the resources in next exercises.

   ![](./images/arcconnect.PNG "")

1. In the Azure Arc Data Controller dashboard, you can see details about the data controller resource such as name, region, connection mode, resource group, subscription, controller endpoint, and namespace. You will also see that we have deployed Direct connection mode of Azure Arc Data controller.

   ![](./images/manage.PNG "")
   
   - **Note**: If you click on the **Open in Azure portal** button you will not able to find the resources because we have not upload any logs to azure portal and without uploading logs to azure, we will not be able to view the Azure Arc data controller resource in Azure portal.
   

## Task 4: Create Log anaytics workspace to upload logs, metric and usages to Azure Monitor. 

In this task you will create a log analytics workspace to upload logs for your Azure Arc enabled SQL managed instances and Azure Arc enabled PostgreSQL Hyperscale server groups to Azure Monitor and view your logs in Azure portal.

1. In the command prompt run the following command to login to azure. On the sign-in page enter the username and password, you can find the username and password from the environment details tab.

   ```BASH
   az login
   ```

   ![](./images/Az-login.PNG "")

1. In the command prompt run the following command to create a log analytics workspace. 

   >**Note**: Please make sure to replace the SUFFIX with **azure-arc-data-SUFFIX** and workspace name. You can find resource group name from the environment details tab and for workspace name enter a globally unique value.

   ```BASH
   az monitor log-analytics workspace create --resource-group azure-arc-data-SUFFIX --workspace-name <Unique name of workspace>
   ```

   ![](./images/Create-logWorkspace.PNG "")

   
1. From the output window copy the **customerID** value and save the value locally in the text file, you will use these values in the later part of the lab.


1. Now run the following command to retrieve the access keys required to connect to your log analytics workspace. Make sure to replace resource group name and workspace name

   ```BASH
     az monitor log-analytics workspace get-shared-keys --resource-group MyResourceGroup --workspace-name <Unique name of workspace>
   ```

   ![](./images/LogWorkspace-Keys.PNG "")
   
1. From the output window copy the **"primarySharedKey** value and save the value locally in the text file, you will use these values in the later part of the lab.

1. In the command prompt, replace the **customerId**, **primarySharedKey** in the following command with the values which you copied earlier and run it. This command saves the customerId and primarySharedKey values in an environment variable to use later in the lab.

   ```BASH
   SET WORKSPACE_ID=<customerId>
   SET WORKSPACE_SHARED_KEY=<primarySharedKey>
   ```

   ![](./images/Set-LogWorkspace-IDKeys.PNG "")

1. Run the following command to set the SPN authority URL in an environment variable.

   ```BASH
   SET SPN_AUTHORITY=https://login.microsoftonline.com
   ```

   ![](./images/Set-client-IDs.PNG "")

1. Now run the following command to make sure that all environment variables required are set.

   ```BASH
   echo %WORKSPACE_ID%
   echo %WORKSPACE_SHARED_KEY%
   echo %SPN_TENANT_ID%
   echo %SPN_CLIENT_ID%
   echo %SPN_CLIENT_SECRET%
   echo %SPN_AUTHORITY%
   ```
  - **Note**: We have already added the variables of Service principal details, So you dont have to add these variables value.
   ![](./images/Echo-env-var.PNG "")

1. Now you have created the **Log Analytics workspaces** but you can't upload any usages or logs because we don't have any resources created under Azure Arc data controller. we will deploy the resources and upload the Logs and usages in next exercises.  

   





## After this exercise, you have got familiar with the below exercises
   - Deploying Azure Arc Data controller on to Azure Kubernetes Cluster(AKS) 
   - Getting started with the existing Kubernetes cluster
   - Connect to the data controller using Azure Data Studio/ Azure Data CLI
   - Monitor with Data Controller Dashboard


   
